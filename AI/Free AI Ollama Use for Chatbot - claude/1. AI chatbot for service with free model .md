# Free Lightweight AI Chatbot with Database Caching

## Overview
This solution uses **Ollama** (free, runs locally) with a small AI model + Redis caching to avoid repeated database queries. Perfect for your 4-core 8GB VPS!

## Step 1: Add Ollama Service to Docker Stack

### Update your docker-compose.yml:
```yaml
version: '3.8'
services:
  # Your existing services...
  
  # Add Ollama AI Service
  ollama:
    image: ollama/ollama:latest
    deploy:
      replicas: 1
      resources:
        limits:
          memory: 2G  # Limit memory usage
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - laravel_network
    environment:
      - OLLAMA_KEEP_ALIVE=5m
      - OLLAMA_HOST=0.0.0.0:11434
    command: serve

  # Add to your app service environment
  app:
    image: instasure-dockerized_app:latest
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
    working_dir: /var/www/html
    environment:
      # Your existing environment variables...
      
      # Add AI Chatbot Configuration
      - AI_ENABLED=true
      - AI_MODEL=llama3.2:3b
      - AI_HOST=http://ollama:11434
      - CHATBOT_CACHE_TTL=3600
      - DB_CACHE_ENABLED=true
    # ... rest of your app config

# Add ollama_data volume
volumes:
  mysql_data:
    driver: local
  redis_data:
    driver: local
  ollama_data:  # Add this
    driver: local

networks:
  laravel_network:
    driver: overlay
    attachable: true
```

## Step 2: Install Required Packages

### Add to your Laravel app (run in container):
```bash
# Install HTTP client for Ollama
composer require guzzlehttp/guzzle

# Install Laravel package for background jobs (if not already installed)
composer require predis/predis
```

## Step 3: Create Database Cache Manager

### Create the cache manager:
```php
<?php
// app/Services/DatabaseCacheManager.php
namespace App\Services;

use Illuminate\Support\Facades\Redis;
use Illuminate\Support\Facades\DB;
use Illuminate\Support\Facades\Log;

class DatabaseCacheManager
{
    const CACHE_KEY_PREFIX = 'chatbot_db:';
    const CACHE_VERSION_KEY = 'chatbot_db:version';
    const CACHE_TTL = 3600; // 1 hour

    public function cacheAllData()
    {
        try {
            $startTime = microtime(true);
            
            // Cache Users
            $users = DB::table('users')
                ->select('id', 'name', 'email', 'phone', 'created_at', 'status')
                ->get()
                ->toArray();
            Redis::setex(self::CACHE_KEY_PREFIX . 'users', self::CACHE_TTL, json_encode($users));

            // Cache Orders
            $orders = DB::table('orders as o')
                ->leftJoin('users as u', 'o.user_id', '=', 'u.id')
                ->select('o.id', 'o.status', 'o.total', 'o.created_at', 'o.user_id', 'u.name as customer_name', 'u.email as customer_email')
                ->get()
                ->toArray();
            Redis::setex(self::CACHE_KEY_PREFIX . 'orders', self::CACHE_TTL, json_encode($orders));

            // Cache Claims
            $claims = DB::table('claims as c')
                ->leftJoin('users as u', 'c.user_id', '=', 'u.id')
                ->select('c.id', 'c.claim_number', 'c.status', 'c.amount', 'c.type', 'c.created_at', 'c.updated_at', 'u.name as customer_name', 'u.email as customer_email')
                ->get()
                ->toArray();
            Redis::setex(self::CACHE_KEY_PREFIX . 'claims', self::CACHE_TTL, json_encode($claims));

            // Cache Packages
            $packages = DB::table('packages')
                ->select('id', 'name', 'category', 'price', 'description', 'coverage_details', 'active')
                ->where('active', 1)
                ->get()
                ->toArray();
            Redis::setex(self::CACHE_KEY_PREFIX . 'packages', self::CACHE_TTL, json_encode($packages));

            // Update cache version
            Redis::incr(self::CACHE_VERSION_KEY);
            
            $endTime = microtime(true);
            Log::info("Database cache refreshed in " . round(($endTime - $startTime) * 1000, 2) . "ms");
            
            return true;
        } catch (\Exception $e) {
            Log::error("Failed to cache database: " . $e->getMessage());
            return false;
        }
    }

    public function getCachedData($table)
    {
        try {
            $data = Redis::get(self::CACHE_KEY_PREFIX . $table);
            return $data ? json_decode($data, true) : [];
        } catch (\Exception $e) {
            Log::error("Failed to get cached data for {$table}: " . $e->getMessage());
            return [];
        }
    }

    public function getCacheVersion()
    {
        return (int) Redis::get(self::CACHE_VERSION_KEY) ?: 0;
    }

    public function isCacheExpired($table)
    {
        return !Redis::exists(self::CACHE_KEY_PREFIX . $table);
    }

    public function invalidateCache()
    {
        $keys = Redis::keys(self::CACHE_KEY_PREFIX . '*');
        if (!empty($keys)) {
            Redis::del($keys);
        }
        $this->cacheAllData();
    }
}
```

## Step 4: Create AI Service for Ollama

### Create Ollama service:
```php
<?php
// app/Services/OllamaAiService.php
namespace App\Services;

use GuzzleHttp\Client;
use Illuminate\Support\Facades\Log;

class OllamaAiService
{
    protected $client;
    protected $host;
    protected $model;

    public function __construct()
    {
        $this->client = new Client(['timeout' => 30]);
        $this->host = config('app.ai_host', 'http://ollama:11434');
        $this->model = config('app.ai_model', 'llama3.2:3b');
    }

    public function generateResponse($prompt, $context = [])
    {
        try {
            $systemPrompt = $this->buildSystemPrompt($context);
            $fullPrompt = $systemPrompt . "\n\nUser Question: " . $prompt . "\n\nAssistant Response:";

            $response = $this->client->post($this->host . '/api/generate', [
                'json' => [
                    'model' => $this->model,
                    'prompt' => $fullPrompt,
                    'stream' => false,
                    'options' => [
                        'temperature' => 0.7,
                        'top_p' => 0.9,
                        'num_predict' => 300
                    ]
                ]
            ]);

            $result = json_decode($response->getBody(), true);
            return $result['response'] ?? 'Sorry, I could not generate a response.';

        } catch (\Exception $e) {
            Log::error("Ollama AI Error: " . $e->getMessage());
            return "Sorry, I'm experiencing technical difficulties. Please try again later.";
        }
    }

    protected function buildSystemPrompt($context)
    {
        $prompt = "You are a helpful customer service assistant for InstaSure Insurance Company.

INSTRUCTIONS:
- Be polite, professional, and concise
- Answer based only on the provided database information
- If information is not available, say so clearly
- Don't make up information
- Format responses in a friendly, easy-to-read way

AVAILABLE DATABASE INFORMATION:";

        if (!empty($context['users'])) {
            $prompt .= "\n\nCUSTOMERS/USERS:\n";
            foreach (array_slice($context['users'], 0, 5) as $user) {
                $prompt .= "- ID: {$user['id']}, Name: {$user['name']}, Email: {$user['email']}\n";
            }
            if (count($context['users']) > 5) {
                $prompt .= "- ... and " . (count($context['users']) - 5) . " more customers\n";
            }
        }

        if (!empty($context['orders'])) {
            $prompt .= "\nORDERS:\n";
            foreach (array_slice($context['orders'], 0, 5) as $order) {
                $prompt .= "- Order #{$order['id']}, Status: {$order['status']}, Total: ${$order['total']}, Customer: {$order['customer_name']}\n";
            }
            if (count($context['orders']) > 5) {
                $prompt .= "- ... and " . (count($context['orders']) - 5) . " more orders\n";
            }
        }

        if (!empty($context['claims'])) {
            $prompt .= "\nINSURANCE CLAIMS:\n";
            foreach (array_slice($context['claims'], 0, 5) as $claim) {
                $prompt .= "- Claim #{$claim['id']}, Status: {$claim['status']}, Amount: ${$claim['amount']}, Type: {$claim['type']}\n";
            }
            if (count($context['claims']) > 5) {
                $prompt .= "- ... and " . (count($context['claims']) - 5) . " more claims\n";
            }
        }

        if (!empty($context['packages'])) {
            $prompt .= "\nINSURANCE PACKAGES:\n";
            foreach ($context['packages'] as $package) {
                $prompt .= "- {$package['name']} ({$package['category']}): ${$package['price']}\n";
            }
        }

        return $prompt;
    }

    public function checkConnection()
    {
        try {
            $response = $this->client->get($this->host . '/api/tags');
            return $response->getStatusCode() === 200;
        } catch (\Exception $e) {
            return false;
        }
    }
}
```

## Step 5: Create Chatbot Controller

### Simple, efficient chatbot controller:
```php
<?php
// app/Http/Controllers/ChatbotController.php
namespace App\Http\Controllers;

use App\Http\Controllers\Controller;
use App\Services\DatabaseCacheManager;
use App\Services\OllamaAiService;
use Illuminate\Http\Request;
use Illuminate\Support\Facades\Cache;

class ChatbotController extends Controller
{
    protected $cacheManager;
    protected $aiService;

    public function __construct(DatabaseCacheManager $cacheManager, OllamaAiService $aiService)
    {
        $this->cacheManager = $cacheManager;
        $this->aiService = $aiService;
    }

    public function chat(Request $request)
    {
        $request->validate([
            'message' => 'required|string|max:500',
            'session_id' => 'nullable|string'
        ]);

        // Check if we need to refresh cache
        if ($this->cacheManager->isCacheExpired('users')) {
            $this->cacheManager->cacheAllData();
        }

        // Get all cached data
        $context = [
            'users' => $this->cacheManager->getCachedData('users'),
            'orders' => $this->cacheManager->getCachedData('orders'),
            'claims' => $this->cacheManager->getCachedData('claims'),
            'packages' => $this->cacheManager->getCachedData('packages')
        ];

        // Filter context based on user question (for efficiency)
        $context = $this->filterRelevantContext($request->message, $context);

        // Generate AI response
        $response = $this->aiService->generateResponse($request->message, $context);

        return response()->json([
            'success' => true,
            'response' => $response,
            'session_id' => $request->session_id ?: uniqid(),
            'cache_version' => $this->cacheManager->getCacheVersion()
        ]);
    }

    protected function filterRelevantContext($message, $context)
    {
        $message = strtolower($message);
        $filtered = [];

        // Always include packages for general questions
        $filtered['packages'] = $context['packages'];

        // Include relevant data based on keywords
        if (preg_match('/order|purchase|buy/', $message)) {
            $filtered['orders'] = array_slice($context['orders'], 0, 10); // Limit for efficiency
        }

        if (preg_match('/claim|insurance|policy/', $message)) {
            $filtered['claims'] = array_slice($context['claims'], 0, 10);
        }

        if (preg_match('/user|customer|account|profile/', $message)) {
            $filtered['users'] = array_slice($context['users'], 0, 10);
        }

        // If asking for specific ID, filter to that ID only
        if (preg_match('/\b(\d+)\b/', $message, $matches)) {
            $id = $matches[1];
            
            if (isset($context['orders'])) {
                $filtered['orders'] = array_filter($context['orders'], fn($item) => $item['id'] == $id);
            }
            if (isset($context['claims'])) {
                $filtered['claims'] = array_filter($context['claims'], fn($item) => $item['id'] == $id);
            }
            if (isset($context['users'])) {
                $filtered['users'] = array_filter($context['users'], fn($item) => $item['id'] == $id);
            }
        }

        return $filtered;
    }

    public function refreshCache()
    {
        $success = $this->cacheManager->cacheAllData();
        
        return response()->json([
            'success' => $success,
            'message' => $success ? 'Cache refreshed successfully' : 'Failed to refresh cache',
            'cache_version' => $this->cacheManager->getCacheVersion()
        ]);
    }

    public function status()
    {
        return response()->json([
            'ai_connected' => $this->aiService->checkConnection(),
            'cache_version' => $this->cacheManager->getCacheVersion(),
            'cache_status' => [
                'users' => !$this->cacheManager->isCacheExpired('users'),
                'orders' => !$this->cacheManager->isCacheExpired('orders'),
                'claims' => !$this->cacheManager->isCacheExpired('claims'),
                'packages' => !$this->cacheManager->isCacheExpired('packages'),
            ]
        ]);
    }
}
```

## Step 6: Create Database Observers for Auto-Updates

### Create observers to invalidate cache when data changes:
```php
<?php
// app/Observers/CacheInvalidationObserver.php
namespace App\Observers;

use App\Services\DatabaseCacheManager;

class CacheInvalidationObserver
{
    protected $cacheManager;

    public function __construct(DatabaseCacheManager $cacheManager)
    {
        $this->cacheManager = $cacheManager;
    }

    public function created($model)
    {
        $this->invalidateRelevantCache($model);
    }

    public function updated($model)
    {
        $this->invalidateRelevantCache($model);
    }

    public function deleted($model)
    {
        $this->invalidateRelevantCache($model);
    }

    protected function invalidateRelevantCache($model)
    {
        // Schedule cache refresh (don't block the request)
        dispatch(function() {
            $this->cacheManager->cacheAllData();
        })->afterResponse();
    }
}
```

### Register observers in AppServiceProvider:
```php
<?php
// app/Providers/AppServiceProvider.php
namespace App\Providers;

use Illuminate\Support\ServiceProvider;
use App\Observers\CacheInvalidationObserver;
use App\Models\User;
use App\Models\Order;
use App\Models\Claim;
use App\Models\Package;

class AppServiceProvider extends ServiceProvider
{
    public function boot()
    {
        // Register cache invalidation observers
        User::observe(CacheInvalidationObserver::class);
        Order::observe(CacheInvalidationObserver::class);
        Claim::observe(CacheInvalidationObserver::class);
        Package::observe(CacheInvalidationObserver::class);
    }
}
```

## Step 7: Create Simple Frontend Widget

### Lightweight chat widget:
```html
<!-- resources/views/components/simple-chatbot.blade.php -->
<div id="chatbot" class="fixed bottom-4 right-4 z-50">
    <button id="chat-btn" class="w-14 h-14 bg-blue-500 rounded-full shadow-lg text-white hover:bg-blue-600 transition-all">
        üí¨
    </button>
    
    <div id="chat-box" class="hidden absolute bottom-16 right-0 w-80 h-96 bg-white rounded-lg shadow-xl border">
        <div class="bg-blue-500 text-white p-3 rounded-t-lg">
            <h4 class="font-semibold">InstaSure Support</h4>
            <button id="close-chat" class="absolute top-3 right-3 text-white">&times;</button>
        </div>
        
        <div id="messages" class="h-72 p-3 overflow-y-auto space-y-2"></div>
        
        <div class="p-3 border-t flex gap-2">
            <input id="user-input" type="text" placeholder="Ask me anything..." 
                   class="flex-1 border rounded-lg px-3 py-2 text-sm focus:outline-none focus:ring-2 focus:ring-blue-500">
            <button id="send-btn" class="bg-blue-500 text-white px-4 py-2 rounded-lg hover:bg-blue-600 text-sm">
                Send
            </button>
        </div>
    </div>
</div>

<script>
document.addEventListener('DOMContentLoaded', function() {
    const chatBtn = document.getElementById('chat-btn');
    const chatBox = document.getElementById('chat-box');
    const closeChat = document.getElementById('close-chat');
    const messages = document.getElementById('messages');
    const userInput = document.getElementById('user-input');
    const sendBtn = document.getElementById('send-btn');
    
    let sessionId = localStorage.getItem('chat_session') || Date.now().toString();
    localStorage.setItem('chat_session', sessionId);
    
    chatBtn.onclick = () => chatBox.classList.toggle('hidden');
    closeChat.onclick = () => chatBox.classList.add('hidden');
    
    function addMessage(content, isUser = false) {
        const div = document.createElement('div');
        div.className = `p-2 rounded text-sm ${isUser ? 'bg-blue-100 ml-8' : 'bg-gray-100 mr-8'}`;
        div.textContent = content;
        messages.appendChild(div);
        messages.scrollTop = messages.scrollHeight;
    }
    
    function sendMessage() {
        const message = userInput.value.trim();
        if (!message) return;
        
        addMessage(message, true);
        userInput.value = '';
        
        // Show typing
        const typing = document.createElement('div');
        typing.id = 'typing';
        typing.className = 'p-2 rounded text-sm bg-gray-100 mr-8 text-gray-500';
        typing.textContent = 'Thinking...';
        messages.appendChild(typing);
        messages.scrollTop = messages.scrollHeight;
        
        fetch('/api/chatbot/chat', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'X-CSRF-TOKEN': document.querySelector('meta[name="csrf-token"]')?.content || ''
            },
            body: JSON.stringify({message, session_id: sessionId})
        })
        .then(res => res.json())
        .then(data => {
            document.getElementById('typing')?.remove();
            if (data.success) {
                addMessage(data.response);
            } else {
                addMessage('Sorry, something went wrong. Please try again.');
            }
        })
        .catch(() => {
            document.getElementById('typing')?.remove();
            addMessage('Connection error. Please check your internet.');
        });
    }
    
    sendBtn.onclick = sendMessage;
    userInput.onkeypress = (e) => e.key === 'Enter' && sendMessage();
    
    // Initial greeting
    setTimeout(() => addMessage("Hi! I'm your InstaSure assistant. Ask me about orders, claims, or insurance packages!"), 500);
});
</script>
```

## Step 8: Add Routes and Commands

### Add routes:
```php
<?php
// routes/api.php
use App\Http\Controllers\ChatbotController;

Route::post('/chatbot/chat', [ChatbotController::class, 'chat']);
Route::post('/chatbot/refresh-cache', [ChatbotController::class, 'refreshCache']);
Route::get('/chatbot/status', [ChatbotController::class, 'status']);
```

### Create console command for cache warming:
```php
<?php
// app/Console/Commands/WarmChatbotCache.php
namespace App\Console\Commands;

use Illuminate\Console\Command;
use App\Services\DatabaseCacheManager;

class WarmChatbotCache extends Command
{
    protected $signature = 'chatbot:warm-cache';
    protected $description = 'Warm up the chatbot database cache';

    public function handle(DatabaseCacheManager $cacheManager)
    {
        $this->info('Warming up chatbot cache...');
        
        if ($cacheManager->cacheAllData()) {
            $this->info('‚úÖ Cache warmed successfully!');
        } else {
            $this->error('‚ùå Failed to warm cache');
        }
    }
}
```

## Step 9: Deploy and Setup

### 1. Update your docker-compose.yml with the Ollama service

### 2. Deploy the stack:
```bash
docker stack deploy -c docker-compose.yml instasure
```

### 3. Setup Ollama model (run once):
```bash
# Pull the lightweight model (3B parameters, ~2GB)
docker exec -it $(docker ps -q -f name=instasure_ollama) ollama pull llama3.2:3b

# Or use an even smaller model (1.5B parameters, ~1GB)
docker exec -it $(docker ps -q -f name=instasure_ollama) ollama pull phi3:mini
```

### 4. Warm up the cache:
```bash
docker exec -it $(docker ps -q -f name=instasure_app) php artisan chatbot:warm-cache
```

## Step 10: Add to Layout

### Include in your main layout:
```html
<!-- In your main layout file -->
@if(config('app.ai_enabled', true))
    <x-simple-chatbot />
@endif
```

## Performance Benefits:

1. **No Database Queries During Chat** - Everything loaded from Redis
2. **Lightweight AI Model** - Only ~2-3GB RAM usage
3. **Smart Context Filtering** - Only sends relevant data to AI
4. **Auto Cache Updates** - Refreshes when data changes
5. **Efficient for 8GB RAM** - Ollama + Laravel + MySQL + Redis fits comfortably

## Example Customer Interactions:

- "How many orders do I have?" ‚Üí AI searches cached orders
- "What's my claim status for claim #123?" ‚Üí AI finds in cached claims
- "Show me auto insurance packages" ‚Üí AI lists from cached packages
- "What's order #456 status?" ‚Üí AI searches cached orders

The system will be much faster since everything is cached in Redis and the AI model runs locally!
