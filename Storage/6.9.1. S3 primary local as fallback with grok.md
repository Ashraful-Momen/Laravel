To implement a service in your Laravel project that handles S3 connectivity with a fallback to local storage and automatic synchronization when S3 reconnects, you can create a custom storage service. This service will manage file operations, check S3 availability, use the local driver as a fallback, and sync local files to S3 when connectivity is restored. Below is a detailed solution, including the service implementation, folder structure handling, and synchronization logic, tailored to your provided configuration and requirements.

---

### Solution Overview
1. **Filesystem Configuration**: Your `config/filesystem.php` is already set up with S3 and local disks, including a fallback disk. We'll leverage this configuration.
2. **Custom Storage Service**: Create a service class to handle file operations, check S3 connectivity, and fall back to local storage if S3 is unavailable.
3. **Synchronization Logic**: Implement a queue-based job to sync files from the local disk to S3 when connectivity is restored.
4. **Folder Structure**: Ensure the folder structure in `/app/public` (as provided) is mirrored on both local and S3 storage.
5. **Docker Integration**: Use the existing `docker-stack.yml` configuration, ensuring environment variables are correctly set.
6. **Queue for Sync**: Use Laravel's queue system (with Redis, as per your config) to handle synchronization tasks asynchronously.

---

### Step 1: Update `.env` for Storage Configuration
Ensure your `.env` file includes the necessary storage configuration variables, aligning with your `docker-stack.yml` and `config/filesystem.php`. Add these if not already present:

```env
# S3 Configuration
FILESYSTEM_DRIVER=s3
S3_KEY=YIWBL4D04XN2XK6KDD87
S3_SECRET=Ro06JYVkWpkQKqwbAnVrjhRbnNSieIKUIqmn7ZoR
S3_REGION=us-east-1
S3_BUCKET=instasure
S3_URL=https://s3.brilliant.com.bd/instasure
S3_ENDPOINT=https://s3.brilliant.com.bd
S3_USE_PATH_STYLE=true

# Storage Configuration
STORAGE_PRIMARY=s3
STORAGE_FALLBACK=local
STORAGE_SYNC_ENABLED=true
STORAGE_AUTO_RETRY=true
STORAGE_MAX_RETRIES=3
```

These variables are consistent with your `docker-stack.yml` and `config/filesystem.php`.

---

### Step 2: Create the Storage Service
Create a custom storage service to handle file operations, check S3 connectivity, and manage fallback to local storage.

#### File: `app/Services/StorageService.php`
```php
<?php

namespace App\Services;

use Illuminate\Support\Facades\Storage;
use Aws\S3\S3Client;
use Illuminate\Support\Facades\Log;
use Illuminate\Support\Facades\Queue;
use App\Jobs\SyncLocalToS3Job;

class StorageService
{
    protected $primaryDisk;
    protected $fallbackDisk;
    protected $s3Client;
    protected $isS3Available;

    public function __construct()
    {
        $this->primaryDisk = config('filesystems.storage_config.primary_disk', 's3');
        $this->fallbackDisk = config('filesystems.storage_config.fallback_disk', 'local');
        $this->isS3Available = $this->checkS3Connectivity();
    }

    /**
     * Check if S3 is available by attempting to list buckets.
     */
    protected function checkS3Connectivity(): bool
    {
        try {
            $this->s3Client = new S3Client([
                'credentials' => [
                    'key' => config('filesystems.disks.s3.key'),
                    'secret' => config('filesystems.disks.s3.secret'),
                ],
                'region' => config('filesystems.disks.s3.region'),
                'endpoint' => config('filesystems.disks.s3.endpoint'),
                'use_path_style_endpoint' => config('filesystems.disks.s3.use_path_style_endpoint'),
                'version' => 'latest',
            ]);

            $this->s3Client->listBuckets();
            return true;
        } catch (\Exception $e) {
            Log::error('S3 connectivity check failed: ' . $e->getMessage());
            return false;
        }
    }

    /**
     * Store a file, trying S3 first and falling back to local if S3 is unavailable.
     */
    public function putFile($path, $file, $visibility = 'public')
    {
        $disk = $this->isS3Available ? $this->primaryDisk : $this->fallbackDisk;
        try {
            $result = Storage::disk($disk)->putFileAs($path, $file, $file->getClientOriginalName(), $visibility);

            // If stored on local disk, queue a job to sync to S3 later
            if ($disk === $this->fallbackDisk && config('filesystems.storage_config.sync_enabled')) {
                $fullPath = $path . '/' . $file->getClientOriginalName();
                Queue::push(new SyncLocalToS3Job($fullPath, $visibility));
            }

            return $result;
        } catch (\Exception $e) {
            Log::error("Failed to store file on {$disk}: " . $e->getMessage());
            throw $e;
        }
    }

    /**
     * Retrieve a file from the appropriate disk.
     */
    public function getFile($path)
    {
        try {
            if ($this->isS3Available && Storage::disk($this->primaryDisk)->exists($path)) {
                return Storage::disk($this->primaryDisk)->get($path);
            }
            return Storage::disk($this->fallbackDisk)->get($path);
        } catch (\Exception $e) {
            Log::error("Failed to retrieve file: " . $e->getMessage());
            throw $e;
        }
    }

    /**
     * Get the URL for a file.
     */
    public function url($path)
    {
        try {
            if ($this->isS3Available && Storage::disk($this->primaryDisk)->exists($path)) {
                return Storage::disk($this->primaryDisk)->url($path);
            }
            return Storage::disk($this->fallbackDisk)->url($path);
        } catch (\Exception $e) {
            Log::error("Failed to generate URL for file: " . $e->getMessage());
            throw $e;
        }
    }

    /**
     * Sync local files to S3 when connectivity is restored.
     */
    public function syncLocalToS3()
    {
        if (!$this->isS3Available) {
            Log::warning('S3 is not available, cannot sync files.');
            return;
        }

        $localFiles = Storage::disk($this->fallbackDisk)->allFiles();
        foreach ($localFiles as $file) {
            if (!Storage::disk($this->primaryDisk)->exists($file)) {
                try {
                    $fileContent = Storage::disk($this->fallbackDisk)->get($file);
                    $visibility = Storage::disk($this->fallbackDisk)->getVisibility($file);
                    Storage::disk($this->primaryDisk)->put($file, $fileContent, $visibility);
                    Log::info("Synced file to S3: {$file}");

                    // Optionally, delete the local file after successful sync
                    Storage::disk($this->fallbackDisk)->delete($file);
                } catch (\Exception $e) {
                    Log::error("Failed to sync file {$file} to S3: " . $e->getMessage());
                }
            }
        }
    }
}
```

---

### Step 3: Create a Job for Synchronization
Create a queue job to handle syncing individual files from the local disk to S3 when connectivity is restored.

#### File: `app/Jobs/SyncLocalToS3Job.php`
```php
<?php

namespace App\Jobs;

use Illuminate\Bus\Queueable;
use Illuminate\Contracts\Queue\ShouldQueue;
use Illuminate\Foundation\Bus\Dispatchable;
use Illuminate\Queue\InteractsWithQueue;
use Illuminate\Queue\SerializesModels;
use Illuminate\Support\Facades\Storage;
use Illuminate\Support\Facades\Log;

class SyncLocalToS3Job implements ShouldQueue
{
    use Dispatchable, InteractsWithQueue, Queueable, SerializesModels;

    protected $filePath;
    protected $visibility;

    public $tries = 3; // Retry up to 3 times, as per STORAGE_MAX_RETRIES

    public function __construct($filePath, $visibility = 'public')
    {
        $this->filePath = $filePath;
        $this->visibility = $visibility;
    }

    public function handle()
    {
        try {
            // Check if S3 is available
            $s3Client = new \Aws\S3\S3Client([
                'credentials' => [
                    'key' => config('filesystems.disks.s3.key'),
                    'secret' => config('filesystems.disks.s3.secret'),
                ],
                'region' => config('filesystems.disks.s3.region'),
                'endpoint' => config('filesystems.disks.s3.endpoint'),
                'use_path_style_endpoint' => config('filesystems.disks.s3.use_path_style_endpoint'),
                'version' => 'latest',
            ]);

            $s3Client->listBuckets(); // Test connectivity

            // Check if file exists locally and not on S3
            if (Storage::disk('local')->exists($this->filePath) && !Storage::disk('s3')->exists($this->filePath)) {
                $fileContent = Storage::disk('local')->get($this->filePath);
                Storage::disk('s3')->put($this->filePath, $fileContent, $this->visibility);
                Log::info("Synced file to S3: {$this->filePath}");

                // Optionally, delete the local file after successful sync
                Storage::disk('local')->delete($this->filePath);
            }
        } catch (\Exception $e) {
            Log::error("Failed to sync file {$this->filePath} to S3: " . $e->getMessage());
            $this->release(60); // Retry after 60 seconds
        }
    }
}
```

---

### Step 4: Create a Command to Trigger Synchronization
Create an Artisan command to manually or periodically trigger the synchronization of local files to S3.

#### File: `app/Console/Commands/SyncLocalToS3.php`
```php
<?php

namespace App\Console\Commands;

use Illuminate\Console\Command;
use App\Services\StorageService;

class SyncLocalToS3 extends Command
{
    protected $signature = 'storage:sync-s3';
    protected $description = 'Sync local storage files to S3 when connectivity is restored';

    protected $storageService;

    public function __construct(StorageService $storageService)
    {
        parent::__construct();
        $this->storageService = $storageService;
    }

    public function handle()
    {
        $this->info('Starting local to S3 synchronization...');
        $this->storageService->syncLocalToS3();
        $this->info('Synchronization completed.');
    }
}
```

Add this command to your `app/Console/Kernel.php` to schedule it:

#### File: `app/Console/Kernel.php`
```php
<?php

namespace App\Console;

use Illuminate\Console\Scheduling\Schedule;
use Illuminate\Foundation\Console\Kernel as ConsoleKernel;

class Kernel extends ConsoleKernel
{
    protected $commands = [
        \App\Console\Commands\SyncLocalToS3::class,
    ];

    protected function schedule(Schedule $schedule)
    {
        // Run the sync command every 5 minutes if sync is enabled
        if (config('filesystems.storage_config.sync_enabled')) {
            $schedule->command('storage:sync-s3')->everyFiveMinutes();
        }
    }

    protected function commands()
    {
        $this->load(__DIR__.'/Commands');
        require base_path('routes/console.php');
    }
}
```

---

### Step 5: Register the Storage Service
Bind the `StorageService` to the Laravel container for dependency injection.

#### File: `app/Providers/AppServiceProvider.php`
```php
<?php

namespace App\Providers;

use Illuminate\Support\ServiceProvider;
use App\Services\StorageService;

class AppServiceProvider extends ServiceProvider
{
    public function register()
    {
        $this->app->singleton(StorageService::class, function ($app) {
            return new StorageService();
        });
    }

    public function boot()
    {
        //
    }
}
```

---

### Step 6: Using the Storage Service in Your Application
You can use the `StorageService` in your controllers or services to handle file operations. Here's an example:

#### Example: `app/Http/Controllers/FileController.php`
```php
<?php

namespace App\Http\Controllers;

use App\Services\StorageService;
use Illuminate\Http\Request;

class FileController extends Controller
{
    protected $storageService;

    public function __construct(StorageService $storageService)
    {
        $this->storageService = $storageService;
    }

    public function upload(Request $request)
    {
        $request->validate([
            'file' => 'required|file',
            'type' => 'required|in:user,life_and_health,tele_medicine,hdc,motor_insurance,fire_insurance,theft_insurance,device_insurance,travel_insurance,cattle_insurance',
            'subtype' => 'required|in:admin,parent_dealer,child_dealer,package,order,claim',
            'filetype' => 'required|in:img,file',
        ]);

        $path = "instasure/{$request->type}/{$request->subtype}/{$request->filetype}";
        $file = $request->file('file');

        try {
            $filePath = $this->storageService->putFile($path, $file, 'public');
            return response()->json(['path' => $filePath, 'url' => $this->storageService->url($filePath)]);
        } catch (\Exception $e) {
            return response()->json(['error' => 'Failed to upload file'], 500);
        }
    }

    public function getFile($type, $subtype, $filetype, $filename)
    {
        $path = "instasure/{$type}/{$subtype}/{$filetype}/{$filename}";
        try {
            $fileContent = $this->storageService->getFile($path);
            return response($fileContent)->header('Content-Type', mime_content_type($fileContent));
        } catch (\Exception $e) {
            return response()->json(['error' => 'File not found'], 404);
        }
    }
}
```

---

### Step 7: Folder Structure Handling
The folder structure you provided under `/app/public` is mirrored in both local and S3 storage. The `StorageService` ensures that files are stored in the correct paths (e.g., `instasure/user/admin/img/filename.jpg`). When syncing from local to S3, the `syncLocalToS3` method preserves this structure by copying files with their full paths.

To ensure the local fallback disk aligns with your structure, update the `fallback` disk in `config/filesystems.php` to point to the same root as `public`:

#### Update `config/filesystems.php`
```php
'fallback' => [
    'driver' => 'local',
    'root' => storage_path('app/public'), // Align with public disk
    'throw' => false,
],
```

This ensures that files stored locally during S3 downtime are placed in `storage/app/public/instasure/...`, matching the S3 structure.

---

### Step 8: Queue Configuration
Since your `docker-stack.yml` uses Redis as the queue driver (`QUEUE_CONNECTION=redis`), ensure the queue worker is running to process `SyncLocalToS3Job`. Add a queue worker service to your `docker-stack.yml`:

#### Update `docker-stack.yml`
Add a new service for the queue worker:

```yaml
services:
  # ... existing services (app, nginx, mysql, redis, etc.) ...

  queue:
    image: instasure-dockerized_app:latest
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
    working_dir: /var/www/html
    environment:
      - DB_CONNECTION=mysql
      - DB_HOST=mysql
      - DB_PORT=3306
      - DB_DATABASE=laravel_db
      - DB_USERNAME=laravel_user
      - DB_PASSWORD=laravel_password
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - CACHE_DRIVER=redis
      - SESSION_DRIVER=redis
      - QUEUE_CONNECTION=redis
      # S3 Configuration
      - FILESYSTEM_DISK=s3
      - FILESYSTEM_DRIVER=s3
      - AWS_ACCESS_KEY_ID=YIWBL4D04XN2XK6KDD87
      - AWS_SECRET_ACCESS_KEY=Ro06JYVkWpkQKqwbAnVrjhRbnNSieIKUIqmn7ZoR
      - AWS_DEFAULT_REGION=us-east-1
      - AWS_BUCKET=instasure
      - AWS_ENDPOINT=https://s3.brilliant.com.bd
      - AWS_URL=https://s3.brilliant.com.bd/instasure
      - AWS_USE_PATH_STYLE_ENDPOINT=true
      - S3_DRIVER=s3
      - S3_KEY=YIWBL4D04XN2XK6KDD87
      - S3_SECRET=Ro06JYVkWpkQKqwbAnVrjhRbnNSieIKUIqmn7ZoR
      - S3_REGION=us-east-1
      - S3_BUCKET=instasure
      - S3_ENDPOINT=https://s3.brilliant.com.bd
      - S3_USE_PATH_STYLE=true
      - S3_URL=https://s3.brilliant.com.bd/instasure
      - APP_ENV=production
      - APP_DEBUG=false
      - APP_URL=http://36.255.69.72:8080
    volumes:
      - /home/ashraful/gitlab_project/instasure-dockerized:/var/www/html
      - /home/ashraful/gitlab_project/instasure-dockerized/docker/php/local.ini:/usr/local/etc/php/conf.d/local.ini
    networks:
      - laravel_network
    depends_on:
      - mysql
      - redis
    command: php artisan queue:work --tries=3
```

---

### Step 9: Testing and Deployment
1. **Deploy the Updated Stack**:
   ```bash
   docker stack deploy -c docker-stack.yml instasure
   ```

2. **Test File Upload**:
   Use a tool like Postman to upload a file to your `/upload` endpoint, specifying `type`, `subtype`, and `filetype`. Verify that the file is stored on S3 if available, or locally if S3 is down.

3. **Simulate S3 Downtime**:
   Temporarily change the `S3_ENDPOINT` in `.env` to an invalid value to simulate S3 failure. Upload files and verify they are stored locally in `storage/app/public/instasure/...`.

4. **Test Synchronization**:
   Restore the correct `S3_ENDPOINT`, then run:
   ```bash
   php artisan storage:sync-s3
   ```
   Check the logs (`storage/logs/laravel.log`) to confirm that local files are synced to S3 and deleted locally (if configured).

5. **Verify Folder Structure**:
   Check your S3 bucket (`instasure`) and local storage (`storage/app/public`) to ensure the folder structure (`instasure/user/admin/img`, etc.) is maintained.

---

### Step 10: Additional Considerations
- **Logging**: The service logs errors and sync operations to `storage/logs/laravel.log`. Monitor these logs for debugging.
- **Queue Worker**: Ensure the queue worker is always running (`php artisan queue:work`) to process sync jobs.
- **Security**: The `s3-private` disk in your `filesystems.php` can be used for sensitive files. Update the `StorageService` to use `s3-private` for specific paths if needed.
- **Performance**: For large numbers of files, consider chunking the sync process in `syncLocalToS3` to avoid memory issues.
- **Backup**: Regularly back up your S3 bucket and local storage to prevent data loss.

---

### Example Usage
To upload a file to `instasure/user/admin/img`:

```bash
curl -X POST http://36.255.69.72:8080/upload \
  -F "file=@/path/to/image.jpg" \
  -F "type=user" \
  -F "subtype=admin" \
  -F "filetype=img"
```

Response:
```json
{
  "path": "instasure/user/admin/img/image.jpg",
  "url": "https://s3.brilliant.com.bd/instasure/instasure/user/admin/img/image.jpg"
}
```

If S3 is down, the file is stored locally, and a `SyncLocalToS3Job` is queued. When S3 is available, the `storage:sync-s3` command or scheduled task will sync the file to S3.

---

This solution ensures your Laravel application seamlessly switches between S3 and local storage, maintains your folder structure, and synchronizes files when S3 reconnects, all while integrating with your existing Docker setup. Let me know if you need further clarification or additional features!
